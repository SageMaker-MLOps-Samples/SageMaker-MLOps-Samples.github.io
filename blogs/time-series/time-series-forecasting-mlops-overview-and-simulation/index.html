<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="End-to-End MLOps on AWS: Part3.1- Time Series Forecasting: MLOps Overview and Simulation#Authors: Palash Nimodia, Abhishek Tawar, Steffi AndradeLast Edited: 01/07/2023 Previous Blog Link: End-to-End MLOps on AWS: Part1 - IntroductionThis blog is a part of a series of blogs based on MLOps workflows we built. In this blog, we will be talking about the time series solution developed using AWS sagemaker pipeline. For more details and a deeper understanding of MLOps, components used and the types of components; go through our previous blog.">
<meta name="theme-color" content="#FFFFFF">
<meta name="color-scheme" content="light dark"><meta property="og:title" content="E2E MLOps on AWS: Part3.1- TS Forecasting: MLOps Overview and Simulation" />
<meta property="og:description" content="End-to-End MLOps on AWS: Part3.1- Time Series Forecasting: MLOps Overview and Simulation#Authors: Palash Nimodia, Abhishek Tawar, Steffi AndradeLast Edited: 01/07/2023 Previous Blog Link: End-to-End MLOps on AWS: Part1 - IntroductionThis blog is a part of a series of blogs based on MLOps workflows we built. In this blog, we will be talking about the time series solution developed using AWS sagemaker pipeline. For more details and a deeper understanding of MLOps, components used and the types of components; go through our previous blog." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://sagemaker-mlops-samples.github.io/blogs/time-series/time-series-forecasting-mlops-overview-and-simulation/" /><meta property="article:section" content="blogs" />


<title>E2E MLOps on AWS: Part3.1- TS Forecasting: MLOps Overview and Simulation | MLOps On AWS</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.f8de3645fe00591b41524aee174e19edd98a22255a2930a0cdc82a94835ba387.css" integrity="sha256-&#43;N42Rf4AWRtBUkruF04Z7dmKIiVaKTCgzcgqlINbo4c=" crossorigin="anonymous">
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.e51c5ae7c24dc8999f81744a8c829682cb7ee2962b51787672f95e54ea09cde9.js" integrity="sha256-5Rxa58JNyJmfgXRKjIKWgst&#43;4pYrUXh2cvleVOoJzek=" crossorigin="anonymous"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-KCH0X75V1Q"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-KCH0X75V1Q', { 'anonymize_ip': false });
}
</script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><span>MLOps On AWS</span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  

  



  
  <ul>
    
      
    
      
        <li class="book-section-flat" >
          
  
  

  
    <a href="/blogs/" class="">Blogs</a>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/blogs/end-to-end-mlops-on-aws-part1-introduction/" class="">E2E MLOps on AWS: Part1 - Introduction</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-03ef094eb464fab36e40fac2dc8cc6fd" class="toggle"  />
    <label for="section-03ef094eb464fab36e40fac2dc8cc6fd" class="flex justify-between">
      <a role="button" class="">Computer Vision</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/blogs/computer-vision/e2e-mlops-on-aws-p2.1-cv-simulation/" class="">E2E MLOps on AWS: Part2.1 - CV Simulation with Drift &amp; Retraining</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/blogs/computer-vision/e2e-mlops-on-aws-p2.2-cv-components-and-pipelines/" class="">E2E MLOps on AWS: Part2.2 - CV Components and Pipelines Deep Dive</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
      
        <li>
          
  
  

  
    <input type="checkbox" id="section-7520c880a260be5a3e516a3696f68e3b" class="toggle" checked />
    <label for="section-7520c880a260be5a3e516a3696f68e3b" class="flex justify-between">
      <a role="button" class="">Time Series</a>
    </label>
  

          
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/blogs/time-series/time-series-forecasting-mlops-overview-and-simulation/" class="active">E2E MLOps on AWS: Part3.1- TS Forecasting: MLOps Overview and Simulation</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/blogs/time-series/time-series-forecasting-detailed-working-of-pipelines/" class="">E2E MLOps on AWS: Part3.2- TS Forecasting: Detailed working of Pipelines</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/blogs/time-series/time-series-forecasting-components-deep-dive/" class="">E2E MLOps on AWS: Part3.3- TS Forecasting: Components Deep Dive</a>
  

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>E2E MLOps on AWS: Part3.1- TS Forecasting: MLOps Overview and Simulation</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#use-case"><strong>Use Case:</strong></a></li>
    <li><a href="#about-dataset"><strong>About Dataset:</strong></a></li>
    <li><a href="#forecasting-parameters-and-metrics"><strong>Forecasting Parameters and Metrics:</strong></a></li>
    <li><a href="#high-level-workflow"><strong>High Level Workflow:</strong></a></li>
    <li><a href="#simulation"><strong>Simulation:</strong></a>
      <ul>
        <li><a href="#setup"><strong>Setup:</strong></a></li>
        <li><a href="#execution"><strong>Execution:</strong></a></li>
        <li><a href="#conclusions"><strong>Conclusions:</strong></a></li>
      </ul>
    </li>
    <li><a href="#references"><strong>References:</strong></a></li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="end-to-end-mlops-on-aws-part31--time-series-forecasting-mlops-overview-and-simulation">
  End-to-End MLOps on AWS: Part3.1- Time Series Forecasting: MLOps Overview and Simulation
  <a class="anchor" href="#end-to-end-mlops-on-aws-part31--time-series-forecasting-mlops-overview-and-simulation">#</a>
</h1>
<table>
<thead>
<tr>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td>Authors: <a href="https://www.linkedin.com/in/palash-nimodia-94975b4b/" target="_blank" rel="noopener">Palash Nimodia</a>
, <a href="https://www.linkedin.com/in/thinkabhishek/" target="_blank" rel="noopener">Abhishek Tawar</a>
, <a href="https://www.linkedin.com/in/steffi-andrade-8b92a3184/" target="_blank" rel="noopener">Steffi Andrade</a>
</td>
</tr>
<tr>
<td>Last Edited: 01/07/2023</td>
</tr>
<tr>
<td>Previous Blog Link:  <a href="../../end-to-end-mlops-on-aws-part1-introduction/">End-to-End MLOps on AWS: Part1 - Introduction</a>
</td>
</tr>
</tbody>
</table>
<hr>
<p>This blog is a part of a series of blogs based on MLOps workflows we built. In this blog, we will be talking about the time series solution developed using AWS sagemaker pipeline. For more details and a deeper understanding of MLOps, components used and the types of components; go through our <a href="../../end-to-end-mlops-on-aws-part1-introduction/">previous blog</a>
. You can find the solution code repository <a href="https://github.com/SageMaker-MLOps-Samples/MLOps-TS-Forecasting" target="_blank" rel="noopener">here</a>
.</p>
<h2 id="use-case">
  <strong>Use Case:</strong>
  <a class="anchor" href="#use-case">#</a>
</h2>
<p>The problem statement of this use case is to <strong>build an end to end MLOps solution for time series data.</strong> The solution will consist of a training pipeline and an inference pipeline built using sagemaker pipelines. The training pipeline will train an LSTM based forecasting model using the training data and save the model in s3. The inference pipeline will generate forecasts using the trained model in batch mode. It will also detect drift in model, data or both and retrain the model if drift was detected.</p>
<h2 id="about-dataset">
  <strong>About Dataset:</strong>
  <a class="anchor" href="#about-dataset">#</a>
</h2>
<p><strong><em>We used an open source city temperature dataset from kaggle</em></strong>. It contains the daily  average temperature values for multiple cities with few other features. This pipeline is built to forecast temperature of one city at a time hence we filter out data for ‘Birmingham’ city for simulation. The granularity of the dataset was at a daily level. We will forecast the average temperature value as it is the target column. You can download the dataset from this <a href="https://www.kaggle.com/datasets/sudalairajkumar/daily-temperature-of-major-cities" target="_blank" rel="noopener">site</a>
.</p>
<h2 id="forecasting-parameters-and-metrics">
  <strong>Forecasting Parameters and Metrics:</strong>
  <a class="anchor" href="#forecasting-parameters-and-metrics">#</a>
</h2>
<ul>
<li>Based on the granularity of the dataset used, the <strong>forecasting frequency was set to daily level.</strong></li>
<li>The <strong>look back is 15 days</strong> and the <strong>look ahead period is 7 days.</strong></li>
<li>We generated <strong>forecast for one day</strong> after the look ahead period (referred here as inference day/forecast day.)</li>
</ul>
<table>
<thead>
<tr>
<th style="text-align:center"><img src="image1.png" alt="" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Forecasting Period Window</td>
</tr>
</tbody>
</table>
<p><strong><em><!-- raw HTML omitted -->Forecasting Period Window<!-- raw HTML omitted --></em></strong></p>
<ul>
<li>The pipeline will be triggered on a daily basis to <strong>forecast the average temperature <em>(Target column)</em></strong>.</li>
<li>The evaluation metric considered to measure the forecasting accuracy is <strong>MAPE (Mean Average Percentage Error)</strong>. This metric will be used to identify if model drift is detected.</li>
</ul>
<h2 id="high-level-workflow">
  <strong>High Level Workflow:</strong>
  <a class="anchor" href="#high-level-workflow">#</a>
</h2>
<table>
<thead>
<tr>
<th style="text-align:center"><img src="image3.png" alt="" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">End-to-end AWS Sagemaker Pipeline</td>
</tr>
</tbody>
</table>
<p>The forecasting solution consists of two main pipelines: <strong>Training pipeline and Inference pipeline.</strong> Both pipelines consist of four main components that are  tied together in a specific sequence to build the pipeline, they are:</p>
<ul>
<li>Processing</li>
<li>Algorithm</li>
<li>Explainability</li>
<li>Monitoring</li>
</ul>
<p><strong>Inference pipeline:</strong></p>
<ul>
<li>All components in the inference pipeline are run in the <strong>serve mode</strong>. The inference pipeline will <strong>fetch the trained ML model, inference data and pipeline parameters</strong>. Using these inputs it <strong>generates temperature forecast</strong> in <strong>batch mode.</strong></li>
<li>Pipeline will also check for <strong>drift <strong>if the cooling period has passed</strong>. Cooling period</strong> prevents retraining pipeline from being triggered on consecutive days and waits for lookaheads period of time for the forecast from the new model to be evaluated for drift.</li>
<li><strong>If drift is detected, it will trigger the training pipeline</strong> and complete the execution of the inference pipeline.</li>
</ul>
<p><strong>Training pipeline:</strong></p>
<ul>
<li>All components in the training pipeline are run in the <strong>train mode</strong>. Training pipeline takes the latest actuals data (split in to training set and validation set) as input.</li>
<li>The pipeline trains a model and <strong>update the parameter store</strong> with the latest model artifact paths generated. This ensures that in the next run of the inference pipeline it uses the latest model artifacts.</li>
</ul>
<h2 id="simulation">
  <strong>Simulation:</strong>
  <a class="anchor" href="#simulation">#</a>
</h2>
<p>A simulation exercise was planned to test the entire ML lifecycle. For this simulation, we ran the pipeline as they would in an actual production environment. Since we worked with daily level data, we ran the simulation for <strong>14 inference dates,</strong> from <strong>01-03-2020 to 14-03-2020</strong>. The monitoring components can measure both data drift and model drift. We chose the <strong>retraining trigger to be model drift</strong> which is measured by degradation of <strong>MAPE value</strong>.</p>
<p>Each run of the inference pipeline is defined in the table below:</p>
<table>
<thead>
<tr>
<th style="text-align:center"><img src="image5.png" alt="" /></th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">Simulation Run Dates</td>
</tr>
</tbody>
</table>
<h3 id="setup">
  <strong>Setup:</strong>
  <a class="anchor" href="#setup">#</a>
</h3>
<p>The <strong>input data files required</strong> to generate inference for each ‘inference date’ for both pipelines in the simulation were <strong>saved in s3</strong>. When a pipeline runs for a particular inference day it will <strong>fetch the inference or train data file for that day</strong>. Every file was identified by including the corresponding inference date in its nomenclature.</p>
<p>Two lambda functions were created and scheduled. The first lambda function (named &ldquo;Update-inference-date-lambda&rdquo;) was created <strong>to update the inference date</strong> (increment by one day) parameter in the parameter store. This parameter defined the date for which the inference pipeline had to generate inference. The second lambda function (named &ldquo;BT-pipeline-trigger-lambda&rdquo;) was used <strong>to trigger the inference pipeline</strong>. Both lambda functions were <strong>scheduled using event bridge rules</strong>. The event rules were enabled to trigger the first lambda function 2 minutes before the second since this will make sure every new run of inference pipeline is different (next day of the previous run). Also note, eventbridge in scheduled mode cannot pass parameters to pipeline hence lambda (with event bridge rule)  is a better trigger for pipeline.</p>
<h3 id="execution">
  <strong>Execution:</strong>
  <a class="anchor" href="#execution">#</a>
</h3>
<ul>
<li>To run the simulation inference pipeline was scheduled to run every hour, for a period of 14 hours: to generate inference for <strong>14 consecutive days</strong>.</li>
<li>The table above shows the details of all the 14 runs. Before starting the inference pipeline runs we ran the train pipeline to train the model on latest actuals data (till date 22-02-2020).</li>
<li>Inference pipeline also check if the <strong>cooling period</strong> is going on for the trained model which in our case is 7 days (= lookahead period). Hence, we will not check for model drift even in first 7 runs, and so the retraining pipeline will definitely won’t be triggered till 07-03-2020 inference date.</li>
<li>For the first 10 runs no drift was detected. The data had <strong>natural drift</strong> which was <strong>detected on 11th run</strong> (highlighted with green in the table). Therefore, inference pipeline triggers the training pipeline.</li>
<li>The training pipeline then trained a new model (with latest actuals data till 03-03-2020) and save the artifacts in s3, update the parameter store with new artifacts paths generated during re-training.</li>
<li>In the next 3 runs inference pipeline generateed forecast with the new model.</li>
</ul>
<h3 id="conclusions">
  <strong>Conclusions:</strong>
  <a class="anchor" href="#conclusions">#</a>
</h3>
<table>
<thead>
<tr>
<th style="text-align:center"><img src="image2.png" alt="" /></th>
</tr>
</thead>
</table>
<ul>
<li>On the inference pipeline run for 11-03-2020, <strong>model drift was detected</strong> and training pipeline was triggered. There was natural drift in the data to cause model drift and hence there was no need to add external noise to the data.</li>
<li>For the 3 dates which used retrained models, we also generated the forecast for these dates using the older model. This was done to check the effect of model retraining on forecast accuracy. The experiment shows that <strong>accuracy improved for all the dates after retraining.</strong></li>
</ul>
<p>This blog gave you an overview of the end-to-end workflow of the time series forecasting pipeline developed using AWS sagemaker pipelines. In the next blog, we will discuss the working of the end-to-end sagemaker pipeline, the various steps involved and the AWS services used. You can find the next blog <a href="../time-series-forecasting-detailed-working-of-pipelines">here</a>
.</p>
<h2 id="references">
  <strong>References:</strong>
  <a class="anchor" href="#references">#</a>
</h2>
<ul>
<li><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/define-pipeline.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/sagemaker/latest/dg/define-pipeline.html</a>
</li>
<li><a href="https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html" target="_blank" rel="noopener">https://docs.aws.amazon.com/sagemaker/latest/dg/build-and-manage-steps.html</a>
</li>
<li><a href="https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-pipelines/tabular/abalone_build_train_deploy/sagemaker-pipelines-preprocess-train-evaluate-batch-transform.html" target="_blank" rel="noopener">https://sagemaker-examples.readthedocs.io/en/latest/sagemaker-pipelines/tabular/abalone_build_train_deploy/sagemaker-pipelines-preprocess-train-evaluate-batch-transform.html</a>
</li>
<li><a href="https://awstip.com/how-to-automatically-trigger-a-sagemaker-pipeline-using-eventbridge-3b71829a9e5" target="_blank" rel="noopener">https://awstip.com/how-to-automatically-trigger-a-sagemaker-pipeline-using-eventbridge-3b71829a9e5</a>
</li>
</ul>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments"><script src="https://utteranc.es/client.js"
        repo="SageMaker-MLOps-Samples/SageMaker-MLOps-Samples.github.io"
        issue-term="pathname"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script></div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#use-case"><strong>Use Case:</strong></a></li>
    <li><a href="#about-dataset"><strong>About Dataset:</strong></a></li>
    <li><a href="#forecasting-parameters-and-metrics"><strong>Forecasting Parameters and Metrics:</strong></a></li>
    <li><a href="#high-level-workflow"><strong>High Level Workflow:</strong></a></li>
    <li><a href="#simulation"><strong>Simulation:</strong></a>
      <ul>
        <li><a href="#setup"><strong>Setup:</strong></a></li>
        <li><a href="#execution"><strong>Execution:</strong></a></li>
        <li><a href="#conclusions"><strong>Conclusions:</strong></a></li>
      </ul>
    </li>
    <li><a href="#references"><strong>References:</strong></a></li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












